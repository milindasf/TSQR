\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{pgfplots}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newcommand{\R}{\mathbb{R}}

\title{Parla Performance Study}
\author{Milinda Fernando and Geroge Biros}

\begin{document}
\maketitle

\section{Benchmark} 
We use the tall skinny QR (TSQR) decomposition algorithm proposed in \cite{}. For a given matrix $A\in \R^{m\times n}$ we assume $m>>n$. The parallel TSQR algorithm can be summarized as follows. 

\begin{algorithm}
    \caption{TSQR decomposition}
    \begin{algorithmic} 
    \REQUIRE $A \in \R^{m\times n}, m>>n$, $p$ parallel tasks
    \ENSURE $A=QR$ for $Q\in \R^{m\times n }$, $Q^TQ=I$ and $R$ is upper triangular.
    \STATE $Ar \leftarrow Partition(A,p)$
    \STATE $Q1r,R1r \leftarrow QR(Ar)$
    \STATE $R1 \leftarrow Gather(R1r,p)$
    \STATE $Q2,R \leftarrow Qr(R1)$
    \STATE $Q2r \leftarrow Partition(Q2r)$ \COMMENT{Same parition bounds as $A$}
    \STATE $Q\leftarrow Q1r \times Q2r$
    \RETURN $Q,R$
    \end{algorithmic}
\end{algorithm}

\section{Implementation}
The following 3 implementations are considered in this performance evaluation. 
\begin{itemize}
    \item Parla QR + Cupy
    \item Python threading + Cupy
    \item Python MPI + Cupy
\end{itemize}

\section{Experimental setup}
\begin{itemize}
    \item The experiments are conducted in Frontera, GPU cluster, where single node consists of Two Intel Xeon E5-2620 v4 (“Broadwell”) with four NVIDIA Quadro RTX5000 GPUs.
\end{itemize}

\section{Results}
\textbullet~ \textbf{Note}: In this experiment, Parla block size was increased with the number of rows in the matrix, such that we get four tasks for 4 GPUs. 

\begin{figure}[!tbhp]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                ybar, 
                symbolic x coords={1K,10K,100K,1000K},
                xtick=data,
                width=15cm,
                height=5cm,
                grid=major,
                xlabel={number of rows}, ylabel={runtime (s)},
                legend pos= north west,legend columns=2,
            ]
            \addplot[bar shift=-1.2cm,fill=green!30] table[x={Rows},y={total_max}]{dat/frontera_mpi_gpu_v1.dat};
            \addplot[bar shift=-0.8cm,fill=green!70] table[x={Rows},y={total_max}]{dat/frontera_mpi_gpu_v3.dat};
            \addplot[bar shift=-0.4cm,fill=blue!30] table[x={Rows},y={total}]{dat/frontera_sm_gpu.dat};
            \addplot[bar shift=0.0cm,fill=orange!30] table[x={Rows},y={total}]{dat/frontera_parla_gpu_t4.dat};
            \addplot[bar shift=0.4cm,fill=red!30] table[x={Rows},y={total}]{dat/frontera_parla_gpu_t8.dat};
            \addplot[bar shift=0.8cm,fill=yellow!30] table[x={Rows},y={total}]{dat/frontera_parla_gpu_t16.dat};
            \legend{MPI + Cupy (qr2 in GPU),MPI + Cupy (qr2 in CPU), Threads + Cupy, Parla + Cupy (4 tasks), Parla + Cupy (8 tasks), Parla + Cupy (16 tasks) }
        \end{axis}
    \end{tikzpicture}
    \caption{Single node performance for TSQR algorithm implemented using Cupy where the parallelism achieved by, Python MPI, Python threading and Parla framework in Frontera GPU cluster. For this experiment matrix column size was fixed at 100 columns.}
\end{figure}

\subsection{Performance analysis}
\begin{itemize}
    \item In Parla, for a given problem size, overall performance is dependent on the number of task created. I think the optimal performance depends on the balance between the task creation overhead and ability to overlap execution in tasks (i.e., overlap between data movement and computations)
    \item Parla runtime grows with the number of tasks in task space. The above is expected, since the overhead of the task creation and scheduling increases with the number of tasks. 
\end{itemize}
    

    
\end{document}